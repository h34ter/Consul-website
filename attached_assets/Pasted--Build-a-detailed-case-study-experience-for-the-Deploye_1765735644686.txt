"Build a detailed case study experience for the Deployed Systems section. When a user clicks a case study card or the view case study, a modal/full-page view opens showing the case study with interactive checkpoints.
Design requirements (MUST follow exactly)
Modal/Page Structure:
White background (same as site: var(--color-surface))
Max width: 900px, centered.
Padding: 48px on desktop, 24px on mobile.
Top: 'X' close button (top-right corner) in gray, click closes modal.
Bottom: A footer with 'View Product' CTA button (primary, rounded, scrolls to #book or routes to /book).
Typography & Spacing:
Use existing design system (same font, sizing, colors as case study grid).
Generous whitespace between sections.
Line-height: relaxed (comfortable reading).
Checkpoint Visual Design:
4 checkpoints (Hidden Constraint, Discovery, Blueprint, Results).
Each checkpoint has:
Small uppercase label (e.g., 'Checkpoint 01') in gray (var(--color-text-secondary)).
Bold headline (title of checkpoint).
Body text (full checkpoint content).
Visual separator between checkpoints (thin line, subtle).
Checkpoints are clickable/expandable OR all visible at once (your choice, but recommend all visible for premium feel).
Subtle icon or number badge (01, 02, 03, 04) before each checkpoint title.
Color scheme:
Background: var(--color-surface) (white/cream).
Text: var(--color-text) (dark gray/charcoal).
Headings: bold, dark.
Checkpoint labels: muted gray.
Accent: use var(--color-primary) (teal) for icons/badges if any.
Mobile responsiveness:
Checkpoints stack vertically (already happening).
Font sizes scale down gracefully.
Close button always accessible.
Footer CTA always sticky at bottom (visible without scrolling on mobile).
Content structure
Use these 4 case studies (paste exactly as given):
EstateSync — Agent OS
Category: 'Real Estate Automation'
Headline: 'Properties matched, clients reached, deals closed — without the manual work.'
Hidden Constraint: 'Agents were losing deals because property matching was manual and slow. A listing would come in, an agent would manually search their database, spend hours on emails, and by then the lead was already working with someone else. The real cost: missed commissions, lost market share, and agents working 60+ hour weeks just to stay competitive.\n\nWhat was actually broken:\n- Property matching took 2–4 hours per new listing (manual database search + filtering).\n- Outreach was templated and impersonal (low response rates, ~8%).\n- Client follow-ups relied on human memory (many leads fell through the cracks).\n- No visibility into which listings matched which client profiles.'
Discovery: 'During the audit, we mapped the entire agent workflow: lead intake → property search → outreach → follow-up → deal close. We discovered that agents were spending 60% of their time on activities that could be automated, and their biggest fear was losing personal touch (we solved that by keeping the agent's voice in every message).\n\nKey insight:\nThe bottleneck wasn't complexity—it was speed. Agents needed to match clients to properties in minutes, not hours, and send personalized outreach automatically while they focused on closing.'
Blueprint: 'System architecture:\n1) Property Matching Engine: Real-time matching of new listings against stored client preferences (location, price, property type, timeline).\n2) Personalized Outreach Generator: AI-powered emails customized to each client's saved preferences and communication history.\n3) Agent Dashboard: One central place to see matched leads, outreach status, follow-up reminders, and deal stage.\n4) Automated Follow-up System: Reminders for agents to follow up, with templated messages they can customize.\n5) CRM Integration: Syncs with existing agent tools (email, calendar, MLS data).\n\nKey decisions:\n- Matching runs in real-time so agents see opportunities as they happen.\n- Messages are agent-customizable (not robotic) to maintain personal brand.\n- Dashboard shows only actionable items (matched leads, pending follow-ups).'
Results: 'Before:\n- Average time to match a lead: 2–4 hours.\n- Manual outreach response rate: ~8%.\n- Agents worked 60+ hour weeks.\n- Deal close rate: ~15% of matched leads.\n\nAfter:\n- Average time to match a lead: 2 minutes (system-generated).\n- Automated outreach response rate: 23% (personalized messages converted better).\n- Agents freed up 20+ hours per week to focus on closing and client relationships.\n- Deal close rate: 38% of matched leads (agents could nurture more leads).\n\nClient quote:\n"This system replaced the most tedious part of my job. I'm now closing 2–3 deals per week instead of 1, and I'm actually enjoying the work again." — Real Estate Agent Partner'
Client Command Center
Category: 'Customer Experience Automation'
Headline: 'Onboarding, support, updates — all in one place. No confusion, no delays.'
Hidden Constraint: 'Client onboarding was chaos. New clients were invited to Slack, sent links to resources scattered across emails, Notion pages, and videos, asked to fill out forms in multiple places, and then didn't know what to do next. Support issues got lost in DMs. Admins didn't know who needed help or what stage clients were at. Result: 40% of new clients fell off before completing onboarding, and admins spent 3+ hours per week chasing people down.\n\nWhat was actually broken:\n- Resources scattered across 5+ platforms (Slack, email, Notion, Loom, Google Drive).\n- New clients had no structured onboarding path (they got overwhelmed).\n- Support tickets got buried in DMs (no tracking, no priority).\n- Admins had zero visibility into client progress.\n- No record of conversations or milestones (hard to track success or debug issues).'
Discovery: 'We tracked 20 new client onboardings and found they averaged 15+ touchpoints (emails, DMs, form fills, video links) before they understood what to do. Clients reported feeling "lost" and "not knowing what's expected." Admins were reactive (answering the same questions 5+ times) instead of proactive.\n\nKey insight:\nThe problem wasn't the content—it was the delivery. Clients needed ONE place (a private channel), ONE checklist, ONE bot to answer questions, and clear progress visibility.'
Blueprint: 'System architecture:\n1) Private Client Channel: Auto-created for each new client (client + admins + bot only).\n2) Automated Onboarding Checklist: Step-by-step guides with timestamps and clear "done" indicators.\n3) Support Bot: Responds to client questions in real-time (trained on FAQs, previous conversations).\n4) Admin Dashboard: Real-time visibility into each client's progress, pending issues, and action items.\n5) Auto-Archiving & Export: All conversations logged to a database for compliance and future reference.\n6) Milestone Tracking: System automatically notes when clients complete onboarding, hit 30-day mark, etc.\n\nKey decisions:\n- Everything happens in one Slack channel (zero platform switching).\n- Checklist is numbered and visual (they can see progress).\n- Bot answers 80% of common questions (admins only jump in for escalations).\n- Admins get daily digest emails (pending issues + client status).'
Results: 'Before:\n- New client onboarding completion rate: 60% (40% dropped off).\n- Average time to resolve a support question: 8 hours (async DM delays).\n- Admin time spent on onboarding per week: 3+ hours.\n- Zero visibility into client progress or blockers.\n\nAfter:\n- New client onboarding completion rate: 94% (only 6% drop-off, mostly for fit reasons).\n- Average time to resolve a support question: 15 minutes (bot responds instantly).\n- Admin time spent on onboarding per week: 20 minutes (system handles 80%).\n- Real-time visibility into every client's progress and blockers.\n\nClient testimonial:\n"Everything I needed was in one place. I knew exactly what to do and when. The bot answered my questions faster than I could type them. Onboarding was actually enjoyable." — Client Success Manager'
Enterprise Licensing Infrastructure
Category: 'Security & Access Control'
Headline: 'License management, entitlements, fraud prevention — enterprise-grade, zero manual overhead.'
Hidden Constraint: 'Paid software users were sharing licenses, reselling access, or running instances they weren't entitled to. There was no way to detect it. License keys were issued manually (error-prone), revocation took days (people could still use after cancellation), and audits were nightmares. The real cost: 20–30% revenue leakage through unlicensed usage, no compliance trail, and constant manual support overhead.\n\nWhat was actually broken:\n- License keys were issued manually (slow, errors, no automation).\n- No real-time usage monitoring (couldn't detect fraud or overuse).\n- Revocation took 48+ hours (users could keep running after cancellation).\n- Zero audit trail (couldn't prove who used what when).\n- Support tickets for license resets/issues took hours to resolve.\n- No way to enforce regional restrictions or tier-based limits.'
Discovery: 'We analyzed 200 license issuances and found 15% had errors (wrong tier, wrong user, issued to wrong email). We traced 30+ instances of license sharing (one key being used from 5+ locations simultaneously). We also found that the revocation process (manual, email-based) had a 3–5 day lag, during which users could still access paid features.\n\nKey insight:\nThe problem wasn't the licensing model—it was the infrastructure. You needed real-time issuance, session-level verification, instant revocation, and a complete audit trail for compliance.'
Blueprint: 'System architecture:\n1) Automated License Generation: Keys generated on demand (tied to customer account, subscription tier, expiry date).\n2) Real-Time Session Verification: Every app launch checks: is this license valid? Has it been revoked? Is it within usage limits?\n3) Usage Monitoring & Fraud Detection: Tracks sessions, detects anomalies (license used from 10 locations in 1 hour = fraud flag).\n4) Instant Revocation: The moment a subscription cancels, all sessions are terminated and new launches are blocked.\n5) Compliance Audit Trail: Every license action logged (issued, used, revoked, shared attempt) with timestamps and user IDs.\n6) Regional & Tier Enforcement: Licenses respect geographic restrictions and feature tier limits (no downgrade hacks).\n\nKey decisions:\n- Verification happens at session-start (not install time) so revocation is instant.\n- Fraud detection is automatic (unusual patterns trigger immediate review).\n- Audit trail is immutable (compliance + legal protection).\n- Dashboard shows revenue impact (unlicensed usage detected, fraud prevented).'
Results: 'Before:\n- License issuance time: 4–8 hours (manual, error-prone).\n- Revocation enforcement time: 48–72 hours (users could still access after cancel).\n- Revenue leakage (unlicensed usage): 25–30%.\n- Support tickets per week (license issues): 12–15.\n- Audit trail: nonexistent (compliance risk).\n\nAfter:\n- License issuance time: 2 minutes (automated).\n- Revocation enforcement time: < 5 minutes (instant session termination).\n- Revenue leakage: < 3% (fraud detection + instant revocation).\n- Support tickets per week (license issues): 0–2 (system self-serves 95%).\n- Audit trail: complete, immutable, exportable (full compliance).\n\nImpact:\n"We recovered €80k in annual revenue just from stopping license sharing. The compliance audit was painless because we had a complete trail. The system paid for itself in the first month." — Operations Director'
Approval & Handoff Engine
Category: 'Operations & Process Automation'
Headline: 'Approvals, routing, handoffs — no more bottlenecks, no more lost requests.'
Hidden Constraint: 'Every decision required manual routing: discounts needed manager approval, refunds needed accounting, hiring needed HR + finance, marketing campaigns needed legal review. Requests got stuck in inboxes, bounced between teams, or fell through the cracks entirely. The real cost: a discount request took 5 days to approve, a refund took 3 weeks, and hiring took 2+ months because approvals were sequential instead of parallel.\n\nWhat was actually broken:\n- Approval requests were sent via email (got lost, forgotten, buried).\n- Routing rules were "in someone's head" (inconsistent, dependent on one person).\n- No priority system (urgent refunds waited behind routine requests).\n- Teams didn't know what was waiting on them (no visibility, no deadlines).\n- No audit trail (couldn't track why something was approved or denied).\n- Escalations were manual and chaotic (phone calls, DMs, desperation).'
Discovery: 'We tracked 100 approval requests over a month and found:\n- Average approval time: 8 days (most time was "waiting in queue").\n- 15% of requests were stuck indefinitely (no one knew who should approve).\n- Only 40% of approvers saw their queue within 24 hours.\n- Urgent requests had no way to jump the line.\n- Zero record of approval decisions (can't audit, can't defend, can't comply).\n\nKey insight:\nThe problem wasn't decision-making—it was visibility and routing. You needed a system that made approval requests visible, routed them to the right person, and tracked every decision.'
Blueprint: 'System architecture:\n1) Smart Request Intake: Forms capture all required info upfront (no back-and-forth).\n2) Automatic Routing: Rules-based (discount > $500 needs VP approval; hiring needs HR + finance).\n3) Parallel Approvals: When possible, approvers work simultaneously (not sequential).\n4) Real-Time Queue Visibility: Each approver sees their pending requests, priority level, and deadline.\n5) Escalation Logic: If not approved in 24 hours, bump to manager. If not approved in 48 hours, bump to director.\n6) Audit Trail: Every approval decision logged (who, what, when, why, any comments).\n7) Notifications: Requestor is updated at every stage (approved, pending, needs more info, denied).\n\nKey decisions:\n- Forms prevent back-and-forth (all required info collected upfront).\n- Approvals are parallel when possible (speed + flexibility).\n- Escalation is automatic (no one slips through cracks).\n- Audit trail is immutable (compliance + accountability).'
Results: 'Before:\n- Average approval time (discount): 5–7 days (mostly waiting).\n- Average approval time (refund): 3+ weeks (bounced between teams).\n- Approval requests lost or forgotten: ~12% per month.\n- Approvers' visibility into queue: none (relied on email inbox).\n- Audit trail: nonexistent (can't defend decisions).\n\nAfter:\n- Average approval time (discount): 4 hours (parallel approvals).\n- Average approval time (refund): 1 day (automatic routing).\n- Approval requests lost or forgotten: 0% (escalation system catches them).\n- Approvers' visibility: real-time dashboard (see queue, priority, deadline).\n- Audit trail: complete, immutable (full compliance + accountability).\n\nImpact:\n"Discount approvals went from 5 days to 4 hours. We can now give customers instant decisions. That alone increased conversion by 12%. The audit trail made our compliance officer's year." — Finance Manager'
Implementation
Route/page structure:
Create a modal component CaseStudyModal.tsx (or full-page route /case-studies/[id]).
Accept the case study ID (estatesync, client-command, licensing, approval-handoff) from URL or state.
Fetch/pull the case study data from the array above.
Render each checkpoint (Hidden Constraint → Discovery → Blueprint → Results) as a separate section.
Data structure (in code):
Create a TypeScript array with this shape:
typescript
type CaseStudy = {
  id: string;
  category: string;
  headline: string;
  checkpoints: {
    hiddenConstraint: string;
    discovery: string;
    blueprint: string;
    results: string;
  };
};

Checkpoint rendering:
Each checkpoint should be:
Preceded by a small uppercase label (e.g., 'Checkpoint 01: Hidden Constraint').
Bold headline (if applicable).
Body text (use the full text provided above, with newlines/bullet points preserved).
Separator (thin line) between checkpoints.
Modal/page behavior:
Close button (top-right, click closes or navigates back).
'View Product' footer button at bottom (primary, rounded, scrolls to #book or routes to /book).
All content visible on first load (no expand/collapse needed, but you can add if you prefer).
Smooth scroll behavior.
Styling:
Use existing design system tokens (colors, fonts, spacing).
Keep generous whitespace.
Ensure readability on mobile.
Dark mode support (use CSS variables).
Output
Return:
Full CaseStudyModal.tsx or case-study-detail.tsx component (with all case study data embedded or imported).
Updated case study grid component that links to the modal/route.
If using modal: modal trigger code (onClick handler + state management).
Any routing changes needed (e.g., dynamic route in Next.js).
No 'Build & Launch' section—jump from Blueprint straight to Results."


