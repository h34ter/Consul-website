
export type Checkpoint = {
  title: string;
  content: string;
};

export type CaseStudy = {
  id: string;
  category: string;
  headline: string;
  checkpoints: {
    hiddenConstraint: string;
    discovery: string;
    blueprint: string;
    results: string;
  };
  footerSection?: {
    title: string;
    content: string;
  };
};

export const caseStudies: CaseStudy[] = [
  {
    id: "estatesync",
    category: "Full stack real estate operations automation",
    headline: "Data matching, intelligent routing, human approval — all automated. No manual work.",
    checkpoints: {
      hiddenConstraint: "A high-volume business was losing opportunities because matching records manually was slow and error-prone. New data would come in, someone would manually search existing records, spend hours filtering, and by then the opportunity was gone. The real cost: missed revenue, lost market share, and teams working insane hours just to stay competitive.\n\nWhat was actually broken:\n- Matching took 2–4 hours per new record (manual database search + filtering).\n- Outreach was templated and impersonal (low response rates, ~8%).\n- Follow-ups relied on human memory (many leads/opportunities fell through cracks).\n- Zero visibility into which new records matched which existing records.\n- No audit trail (couldn't prove who matched what or why).\n- Escalations were manual and chaotic.\n\nSound familiar?\nThis applies whether you're matching:\n- Properties to clients\n- Customers to product recommendations\n- Leads to sales reps\n- Orders to inventory\n- Job candidates to open positions",
      discovery: "During the audit, we mapped the entire workflow: data intake → manual search → decision → outreach → follow-up → conversion. We discovered that the team was spending 60% of their time on activities that could be automated, and their biggest fear was losing personal touch (we solved that by keeping human judgment in every decision).\n\nKey insight:\nThe bottleneck wasn't complexity—it was speed. They needed to match records in minutes, not hours, and send personalized outreach automatically while they focused on closing/conversion.\n\nThe audit revealed:\n- Average time to match a record: 2–4 hours (mostly waiting/searching).\n- Matching accuracy: ~70% (human error, fatigue).\n- Records lost in backlog: ~15% per week (never got matched).\n- Outreach response rate: ~8% (templated, impersonal).\n- Follow-up consistency: ~40% (depends on who remembers).",
      blueprint: "System architecture (kept intentionally generic):\n\nIntelligent Matching Engine\n- Learns from your existing data (what successful matches look like).\n- Real-time matching of new records against stored profiles/criteria.\n- Ranks matches by probability/relevance.\n- Flags anomalies and edge cases for human review.\n\nPersonalized Outreach Generator\n- AI-generates contextual messages based on match quality and user history.\n- Messages are customizable by humans before sending (no auto-send).\n- Maintains brand voice and personal touch.\n- Tracks every message sent (audit trail).\n\nUnified Command Dashboard\n- One place to see all matched records, outreach status, follow-up reminders.\n- Real-time visibility (what's pending, what's in progress, what's done).\n- Customizable views (by team, by priority, by stage).\n\nHuman-in-the-Loop Approval System\n- AI suggests matches and outreach; humans approve before action.\n- Escalation logic for uncertain matches.\n- Complete audit trail (who approved what, when, why).\n\nIntegration Layer\n- Connects to your existing systems (data sources, CRM, communication tools).\n- Custom connectors for your specific data format.\n\nKey decisions:\n- Matching runs in real-time so teams see opportunities as they happen.\n- Messages are generated by AI but approved by humans (maintains control + personal brand).\n- Dashboard shows only actionable items (no noise, pure signal).\n- Every action is logged (compliance + accountability).",
      results: "Before:\n- Average time to match a record: 2–4 hours (manual work).\n- Matching accuracy: ~70% (human error).\n- Records lost in backlog: ~15% per week (never matched).\n- Outreach response rate: ~8% (impersonal, templated).\n- Team working hours: 60+ hour weeks (exhausting).\n\nAfter:\n- Average time to match a record: 2 minutes (system-generated).\n- Matching accuracy: 94%+ (AI learns from historical successes).\n- Records lost: 0% (system catches everything).\n- Outreach response rate: 23%+ (personalized, contextual).\n- Team working hours: 40 hour weeks (freed up 20+ hours for strategic work).\n- Conversion rate: 38% of matched records (up from ~15%) — because the team could now nurture more matches.\n\nClient quote:\n\"This system replaced the most tedious part of our job. We're now closing deals 2–3x faster, and our team is actually happy again. The system does the grunt work, we do the thinking.\" — Operations Lead\n\nRevenue impact:\n- Processed $40M+ in records monthly.\n- Recovered €80k+ in year-one revenue (from matches that would've been lost).\n- Freed up 500+ team hours per month (could redirect to strategy, relationships, closing)."
    },
    footerSection: {
      title: "Why This Architecture Works Across Verticals",
      content: "The system you just saw isn't specific to real estate.\nThe core architecture (intelligent matching + routing + human approval + audit) applies to any high-volume business where you need to:\n- Match records from multiple sources (data integration).\n- Make fast, accurate decisions at scale (matching logic).\n- Keep humans in control (approval layer).\n- Prove what happened (audit trail).\n\nExamples:\n- E-commerce: Match customer behavior to product recommendations. Route to warehouse. Auto-generate fulfillment orders.\n- B2B Services: Match leads to service consultants. Route to available capacity. Auto-generate proposals.\n- Supply Chain: Match orders to production lines. Route to available facilities. Auto-generate work instructions.\n- Staffing: Match candidates to open roles. Route to hiring managers. Auto-generate interview schedules.\n- SaaS: Match accounts to success managers. Route to right team. Auto-generate onboarding sequences.\n\nThe complexity is in the backend.\nEvery business has different:\n- Data sources (where your records come from).\n- Matching rules (what makes a \"good\" match in your world).\n- Approval workflows (who decides, how, when).\n- Compliance requirements (what you need to track/prove).\n\nThis is why this system is custom-built for each deployment. We don't have an off-the-shelf product. We audit your workflow, understand your constraints, and build the matching + routing + approval engine that fits your business exactly.\n\nInterested in how this could work for you? Request an audit. We'll review your current process, identify bottlenecks, and show you exactly how this architecture could apply — with real numbers specific to your business."
    }
  },
  {
    id: "client-lifecycle",
    category: "Customer Experience Automation",
    headline: "Onboarding, support, updates — all in one place. No confusion, no delays.",
    checkpoints: {
      hiddenConstraint: "Client onboarding was chaos. New clients were invited to Slack, sent links to resources scattered across emails, Notion pages, and videos, asked to fill out forms in multiple places, and then didn't know what to do next. Support issues got lost in DMs. Admins didn't know who needed help or what stage clients were at. Result: 40% of new clients fell off before completing onboarding, and admins spent 3+ hours per week chasing people down.\n\nWhat was actually broken:\n- 15+ disparate touchpoints for one onboarding process.\n- No central \"truth\" for client status.\n- Reactive support instead of proactive guidance.",
      discovery: "We tracked 20 new client onboardings and found they averaged 15+ touchpoints (emails, DMs, form fills, video links) before they understood what to do. Clients reported feeling \"lost\" and \"not knowing what's expected.\" Admins were reactive (answering the same questions 5+ times) instead of proactive.\n\nKey insight:\nThe problem wasn't the content—it was the delivery. Clients needed ONE place (a private channel), ONE checklist, ONE bot to answer questions, and clear progress indicators.",
      blueprint: "System architecture:\n1) Private Client Channel: Auto-created for each new client (client + admins + bot only).\n2) Automated Onboarding Checklist: Step-by-step guides with timestamps and clear \"done\" indicators.\n3) Support Bot: Responds to client questions in real-time (trained on FAQs, previous conversations).\n4) Admin Dashboard: Real-time visibility into each client's progress, pending issues, and action items.\n5) Auto-Archiving & Export: All conversations logged and searchable.",
      results: "Before:\n- New client onboarding completion rate: 60% (40% dropped off).\n- Average time to resolve a support question: 8 hours (async DM delays).\n- Admin time spent on onboarding per week: 3+ hours.\n- Zero visibility into client progress or blockers.\n\nAfter:\n- New client onboarding completion rate: 94% (only 6% drop-off, mostly for fit reasons).\n- Average time to resolve a support question: 15 minutes (bot responds instantly).\n- Admin time spent on onboarding per week: < 30 minutes (monitoring only).\n- 100% visibility into every client's status."
    }
  },
  {
    id: "license-control",
    category: "Security & Access Control",
    headline: "License management, entitlements, fraud prevention — enterprise-grade, zero manual overhead.",
    checkpoints: {
      hiddenConstraint: "Paid software users were sharing licenses, reselling access, or running instances they weren't entitled to. There was no way to detect it. License keys were issued manually (error-prone), revocation took days (people could still use after cancellation), and audits were nightmares. The real cost: 20–30% revenue leakage through unlicensed usage, no compliance trail, and constant manual support overhead.\n\nWhat was actually broken:\n- License keys were issued manually via email.\n- No technical enforcement of seat limits.\n- Revocation was a manual database update that didn't kill active sessions.",
      discovery: "We analyzed 200 license issuances and found 15% had errors (wrong tier, wrong user, issued to wrong email). We traced 30+ instances of license sharing (one key being used from 5+ locations simultaneously). We also found that the revocation process (manual, email-based) had a 3–5 day lag, during which users could still access paid features.\n\nKey insight:\nThe problem wasn't the licensing model—it was the infrastructure. You needed real-time issuance, session-level validation, and automated fraud detection hooks.",
      blueprint: "System architecture:\n1) Automated License Generation: Keys generated on demand (tied to customer account, subscription tier, expiry date).\n2) Real-Time Session Verification: Every app launch checks: is this license valid? Has it been revoked? Is it within usage limits?\n3) Usage Monitoring & Fraud Detection: Tracks sessions, detects anomalies (license used from 10 locations in 1 hour = fraud flag).\n4) Instant Revocation: The moment a subscription cancels, all sessions are killed via WebSocket/API push.",
      results: "Before:\n- License issuance time: 4–8 hours (manual, error-prone).\n- Revocation enforcement time: 48–72 hours (users could still access after cancel).\n- Revenue leakage (unlicensed usage): 25–30%.\n- Support tickets per week (license issues): 12–15.\n- Audit trail: nonexistent (compliance risk).\n\nAfter:\n- License issuance time: 2 minutes (automated).\n- Revocation enforcement time: < 5 minutes (instant session termination).\n- Revenue leakage: < 3% (fraud detection blocks sharing).\n- Support tickets: < 1 per week.\n- Full audit trail for every key generation and check."
    }
  },
  {
    id: "approval-engine",
    category: "Operations & Process Automation",
    headline: "Approvals, routing, handoffs — no more bottlenecks, no more lost requests.",
    checkpoints: {
      hiddenConstraint: "Every decision required manual routing: discounts needed manager approval, refunds needed accounting, hiring needed HR + finance, marketing campaigns needed legal review. Requests got stuck in inboxes, bounced between teams, or fell through the cracks entirely. The real cost: a discount request took 5 days to approve, a refund took 3 weeks, and hiring took 2+ months because approvals were sequential instead of parallel.\n\nWhat was actually broken:\n- Approval requests were just emails/Slacks (unstructured).\n- No clear ownership of \"next step\".\n- Sequential processing meant one person on vacation blocked everything.",
      discovery: "We tracked 100 approval requests over a month and found:\n- Average approval time: 8 days (most time was \"waiting in queue\").\n- 15% of requests were stuck indefinitely (no one knew who should approve).\n- Only 40% of approvers saw their queue within 24 hours.\n- Urgent requests had no way to jump the line.\n- Zero record of approval decisions (can't audit, can't defend, can't comply).\n\nKey insight:\nThe problem wasn't decision-making—it was visibility and routing. We needed a system that pushed requests to the right people, allowed parallel approvals, and escalated delays automatically.",
      blueprint: "System architecture:\n1) Smart Request Intake: Forms capture all required info upfront (no back-and-forth).\n2) Automatic Routing: Rules-based (discount > $500 needs VP approval; hiring needs HR + finance).\n3) Parallel Approvals: When possible, approvers work simultaneously (not sequential).\n4) Real-Time Queue Visibility: Each approver sees their pending requests, priority level, and deadline.\n5) Escalation Logic: If not approved in 24 hours, bump to manager. If not acted on, re-route.",
      results: "Before:\n- Average approval time (discount): 5–7 days (mostly waiting).\n- Average approval time (refund): 3+ weeks (bounced between teams).\n- Approval requests lost or forgotten: ~12% per month.\n- Approvers' visibility into queue: none (relied on email inbox).\n- Audit trail: nonexistent (can't defend decisions).\n\nAfter:\n- Average approval time (discount): 4 hours (parallel approvals).\n- Average approval time (refund): 1 day (automatic routing).\n- Approval requests lost: 0% (system tracks everything).\n- Approvers have a dedicated dashboard.\n- Full audit trail of who approved what and when."
    }
  }
];
